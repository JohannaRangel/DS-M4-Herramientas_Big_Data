{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/kzhangkzhang/258d18858889fa97194011a249b74c43\n",
    "\n",
    "https://youtu.be/4Dko5W96WHg?si=NO8dWSxu5mhmZjeP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "  git clone https://github.com/soyHenry/DS-M4-Herramientas_Big_Data.git\n",
    "  cd DS-M4-Herramientas_Big_Data\n",
    "  sudo docker-compose -f docker-compose-v1.yml up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDFS: Configuración de sistema de archivos distribuido para almacenar datos en HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker exec -it namenode bash\n",
    "cd home\n",
    "mkdir Datasets\n",
    "cd Datasets\n",
    "ls #verifico que esten los archivos\n",
    "exit\n",
    "pwd # /home/ubuntu/DS-M4-Herramientas_Big_Data\n",
    "sudo docker cp <path><archivo> namenode:/home/Datasets/<archivo>\n",
    "# sudo docker cp /home/ubuntu/DS-M4-Herramientas_Big_Data namenode:/home/\n",
    "mv /home/Datasets/Datasets/* /home/Datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "  sudo docker exec -it namenode bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "  hdfs dfs -mkdir -p /data\n",
    "  hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "  hdfs dfs -put /home/Datasets/* /data\n",
    "  hdfs dfs -ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    " http://<IP_Anfitrion>:9870/conf\n",
    " http://192.168.1.26:9870/\n",
    "\n",
    "#valores de tamaño de bloque \n",
    " #dfs.blocksize\n",
    " #134217728\n",
    "\n",
    "#valores de factor de réplica\n",
    " #dfs.replication\n",
    " #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hive: Crear tablas en Hive, a partir de los csv ingestados en HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd DS-M4-Herramientas_Big_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker-compose -f docker-compose-v2.yml up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#desde ubuntu\n",
    "sudo docker cp /home/ubuntu/DS-M4-Herramientas_Big_Data/Paso02.hql hive-server:/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker exec -it hive-server bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#me ubico en la raiza del container que fue donde guardo el archivo (salgo de opt cd..)\n",
    "hive -f /Paso02.hql\n",
    "\n",
    "hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "SHOW DATABASES;\n",
    "USE integrador;\n",
    "SHOW TABLES;\n",
    "DROP DATABASE integrador CASCADE;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatos de Almacenamiento: Las tablas creadas en HIVE, deben ser almacenadas en formato Parquet + Snappy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker cp /home/ubuntu/DS-M4-Herramientas_Big_Data/Parquet hive-server:/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker exec -it hive-server \n",
    "cd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "  hdfs dfs -mkdir -p /data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    " hdfs dfs -put /Parquet/Datasets2/. /data2\n",
    "\n",
    "\n",
    " hdfs dfs -mv /data2/Datasets2/* /data2/\n",
    " hdfs dfs -ls /data2\n",
    " hdfs dfs -rm -r  /data2/Datasets2/\n",
    " exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker cp /home/ubuntu/DS-M4-Herramientas_Big_Data/Paso03.hql hive-server:/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker exec -it hive-server bash\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#no funciono con el scrip Paso03.hql, se crearon las tablas manualmente\n",
    "#archivo: creacion_y_de_las_tablas_punto_3_sin_script\n",
    "\n",
    "#hive -f /Paso03.hql\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
